Created the repo and cloned it using vscode

then created an env for the postgre

then we created a docker compose for the postgresql databse and pgadmin - making two services

next, 
we changee the port to 5433 since I already have pgadmin on my pc and it is routed to 5432 already.

THen I used pgadmin to create the server using the details in the .env file after loading my docker up.

Apparently, 
I need to create schemas and base tables since my database is empty. I have created the database while registering the server on pgadmin.

The goal is:
what came in → cleaned → truth → meta/monitoring.

These are the schemas. They should keep things tidy this way:

raw → unprocessed API dumps

staging → cleaned but not final

core → final analytics-ready tables

ops → logs, monitoring, etc.

It's just so we separate the different types of data logically, prevent table-name collisions cos we could have users table in staging and core, and to simplify permissions
It also allows us manage this project when it scales.

Next I created the tables for the core schema - 4 in total
- economic indicator
- air quality
- weather
- alerts

Then one table for the monitoring in the ops schema
- ingestion log

These should be able to sort out the MVP before we go for robustness later


And before I forget, I need to version my sql too so I'll dump my schema into a file and commit it.

Command:
FOr the schema dump:
docker exec -t atlas_db pg_dump -U joshua -s atlas_db > schema.sql

For the full dump i.e. schema and data:
docker exec -t atlas_db pg_dump -U joshua atlas_db > full_dump.sql

For a specific table:
docker exec -t atlas_db pg_dump -U joshua -t core.econ_daily atlas_db > econ_daily.sql

For only data without schema:
docker exec -t atlas_db pg_dump -U joshua --data-only atlas_db > data_dump.sql



After writing the etl script for worldbank loader, I faced an issue with my normalization because I tried to insert a python dictionary into postgresql

so stupid

so I had to alter that econ table's meta column to be type JSONB so I can convert the dictionary to JSON string.

We'll see how that goes

I ran it now and sqlalchemy is asking for named params when I passed the values directly.
I'll change that.

It works now.